<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<HTML>
<HEAD>
<META NAME="generator" CONTENT="http://txt2tags.org">
<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<LINK REL="stylesheet" TYPE="text/css" HREF="/static/fancy.css">
<TITLE>淘宝爬虫原型，基于Gevent</TITLE>
</HEAD><BODY BGCOLOR="white" TEXT="black">
<CENTER>
<H1>淘宝爬虫原型，基于Gevent</H1>
<FONT SIZE="4"><I>作者: roy@rootk.com</I></FONT><BR>
<FONT SIZE="4">2013/5/21</FONT>
</CENTER>

<P></P>
<HR NOSHADE SIZE=1>
<P></P>

  <UL>
  <LI><A HREF="#toc1">1. 项目介绍</A>
  <LI><A HREF="#toc2">2. 结构</A>
    <UL>
    <LI><A HREF="#toc3">2.1. 结构图</A>
    <LI><A HREF="#toc4">2.2. 结构说明</A>
    </UL>
  <LI><A HREF="#toc5">3. 功能说明</A>
  </UL>

<P></P>
<HR NOSHADE SIZE=1>
<P></P>

<A NAME="toc1"></A>
<H1>1. 项目介绍</H1>

<P>
基于python gevent框架的淘宝爬虫原型，支持多个节点之间负载均衡，采用类似与HTTP的协议通信。支持并发控制。
</P>
<P>
用户要求向s.taobao.com查询400个关键词的销量和宝贝总数，10秒内返回内容。
</P>
<P>
目前利用100M的带宽，可以做到平均7秒内返回，总共需要读取大约90MB的内容并经过简单正则匹配和计算。
</P>
<P>
100M的带宽可以完全利用，如果s.taobao.com不限制并发访问数量并且抓取的带宽不限，时间还可以再缩短。
</P>

<A NAME="toc2"></A>
<H1>2. 结构</H1>

<A NAME="toc3"></A>
<H2>2.1. 结构图</H2>

<P>
<IMG ALIGN="middle" SRC="/static/images/crawler/crawler.png" BORDER="0" ALT="">
</P>

<A NAME="toc4"></A>
<H2>2.2. 结构说明</H2>

<UL>
<LI>整个项目建立在gevent为基础的python网络并发框架上。
<LI>Proxy Server和Work Node之间采用简单的文本协议通信，类似与HTTP协议。
<LI>使用queue作为greenlet之间的通讯。
<LI>目前手动控制并发数量，将来会采用信号控制并发数量。
</UL>

<A NAME="toc5"></A>
<H1>3. 功能说明</H1>

<UL>
<LI>Proxy Server负责接收用户的请求，跟根据一个关键词查询s.taobao.com得到最终400个关键词。
<LI>Proxy Server将400个关键词分配到Work Node。
<LI>Work Node接收到实际任务后，启动一定数量的greenlet并发读取s.taobao.com的内容。
<LI>所有Work Node将抓取到的内容返回给Porxy Server。
<LI>Porxy Server将所有返回的内容按照json格式返回给用户，至此一个查询完成。
<P></P>
</UL>

<!-- html code generated by txt2tags 2.6 (http://txt2tags.org) -->
<!-- cmdline: txt2tags -t html index.t2t -->
</BODY></HTML>
